{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3276368e",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Feedforward nets such as MLPs and CNNs assume the samples are independent, but this is not always the case. For example text and sensor data are dependent on the previous data. RNNs help capture the depenency by keeping memory of past data.\n",
    "\n",
    "It works by having hidden states $h_t=f(h_{t-1}, x_t)$. This says that a hidden state depends on the previous hidden state and the current input. This is how RNNs \"remember\" past info.\n",
    "\n",
    "The exact formula is $h_t=f(Wh_{t-1}+Ux_t+b)$, where $f$ is the activation function, $W$ and $U$ are the learnable weight matrices\n",
    "\n",
    "There are multiple types of RNN problems:\n",
    "\n",
    "- One-to-one:\n",
    "    - $x_t \\rightarrow y_t$\n",
    "    - does $h_t=f(Wh_{t-1}+Ux_t+b)$, and then $y_t=g(W_yh_t+c)$\n",
    "    - Same amount inputs and outputs\n",
    "\n",
    "- Many-to-one:\n",
    "    - For example classification\n",
    "    - with $T=2$, $x_1 \\rightarrow h_1$, $x_2 \\rightarrow h_2 \\rightarrow y$\n",
    "    - $y=g(W_yh_t)$\n",
    "\n",
    "- One-to-many:\n",
    "    - $x \\rightarrow z_1$, $z_1 \\rightarrow y_1$, $z_2 \\rightarrow y_2$\n",
    "\n",
    "- Many-to-many (varying lengths):\n",
    "    - $x_1 \\rightarrow h_1$, $x_2 \\rightarrow h_2$, $h_2 \\rightarrow z_0$, $z_0 \\rightarrow z_1$, $z_1 \\rightarrow y_1$, $z_2 \\rightarrow y_2$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
