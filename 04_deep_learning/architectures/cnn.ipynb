{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cd7405",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "This notebook will implement a simple CNN building blocks from scratch. And explain how they differ from fully connected layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf03af",
   "metadata": {},
   "source": [
    "## 1) Convolutional Layer\n",
    "\n",
    "A convolutional layer slides a small filter (kernel) over the input image.\n",
    "At each location, it computes a dot product between the filter and the image patch underneath it.  (A dot product that becomes large when the patch contains the pattern the filter has learned to detect.)\n",
    "\n",
    "This produces a feature map showing where the filter's pattern appears in the image.\n",
    "\n",
    "- The filter's weights are learned during training. (think of it like a small image)\n",
    "\n",
    "- In practice, each filter looks for a specific pattern (e.g., vertical edge, corner).\n",
    "\n",
    "- The output preserves the 2D spatial structure of the image.\n",
    "\n",
    "- The layer sees only local regions at a time (the receptive field).\n",
    "\n",
    "(the padding is a pad (of 0's usually) around the edges of the input image, the stride is the slide size, for example when stride=2 we take the dot product with every other location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cce8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple 2D implementation in numpy\n",
    "\n",
    "def conv2d(input_matrix, kernel, padding, stride):\n",
    "    input_height, input_width = input_matrix.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    h = input_height + 2*padding\n",
    "    w = input_width + 2*padding\n",
    "\n",
    "    # adding padding to the input matrix\n",
    "    padded = np.pad(input_matrix, padding)\n",
    "\n",
    "    # initializing output matrix\n",
    "    output_matrix = np.zeros(((h-kernel_height) // stride+1, (w-kernel_width) // stride+1))\n",
    "\n",
    "    # slide kernel across the image and for each compute the dot product (sum of elementwise products)\n",
    "    for out_i, i in enumerate(range(0, h-kernel_height+1, stride)):\n",
    "        for out_j, j in enumerate(range(0, w-kernel_width+1, stride)):\n",
    "            # elementwise multiply + sum = dot product between kernel and image patch\n",
    "            output_matrix[out_i, out_j] = np.sum((padded[i:i+kernel_height, j:j+kernel_width] * kernel))\n",
    "    \n",
    "    return output_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98428d",
   "metadata": {},
   "source": [
    "That was a 2D (1 channel) example for simplicity. It real examples, an RGB image has multiple channels making it 3D. Also, the batch size affects the dimensionality which makes if 4D.\n",
    "\n",
    "in PyTorch we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66344c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23a955",
   "metadata": {},
   "source": [
    "That example means there are $3 \\cdot 16$ small 3x3 kernels. Each filter consists of in_channels filters. So there are 16 filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5df9e",
   "metadata": {},
   "source": [
    "## Why convolutions are more efficient than fully connected layers\n",
    "\n",
    "Because the convolutional layer shares parameters (the sliding window has the same parameters everywhere), it's a lot more efficient than a fully connected layer.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let's say there is a $32 \\times 32$ RBG image\n",
    "\n",
    "A fully connected layer flattened to 100 neurons would be $(3 \\cdot 32 \\cdot 32) \\cdot 100 = 307200$\n",
    "\n",
    "A convolution layer with $16 $ $3 \\times 3 \\times 3$ filters is $(16 \\cdot 3 \\cdot 3 \\cdot 3)=432$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a64423",
   "metadata": {},
   "source": [
    "## 2) Pooling Layers\n",
    "\n",
    "Another part of CNNs are pooling layers. Commonly average pooling or max pooling. These just reduce dimensions like the following example:\n",
    "\n",
    "Max pooling (2 $\\times$ 2): $\\begin{bmatrix} 3 & 0 & 5 & 2  \\\\ 1 & 2 & 7 & 5 \\\\ 4 & 3 & 2 & 1\\\\ 3 & 1& 0 & 4\\end{bmatrix}$  $\\rightarrow$ $\\begin{bmatrix} 3 & 7  \\\\ 4 & 4\\end{bmatrix}$\n",
    "\n",
    "Pooling layers help with robustness to small spatial changes as well as efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e76ee",
   "metadata": {},
   "source": [
    "## Example of a simple CNN\n",
    "\n",
    "We combine a bunch of conv layers and pooling layers to build a full CNN. The conv layers and pooling layers basically extract features before passing it to the fully connected layers.\n",
    "\n",
    "The example takes as grayscale input of shape 28 $\\times$ 28. Learns to classify these images into 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39a5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNExample(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNExample, self).__init__()\n",
    "        # input shape: (batch_size, 1, 28, 28)\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, 3, padding=1),\n",
    "            nn.BatchNorm2d(20), # Batch norm helps with training stability and speed. Not crucial to understand.\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(20, 20, 3, padding=1),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(20, 20, 3, padding=1),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2) # 28x28 -> 14x14\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(20, 40, 3, padding=1),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(40, 40, 3, padding=1),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(40, 40, 3, padding=1),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2) # 14x14 -> 7x7\n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(40, 60, 3), # 7x7 -> 5x5\n",
    "            nn.BatchNorm2d(60),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(60, 40, 1), # 5x5 -> 5x5\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(40, 20, 1), # 5x5 -> 5x5\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # input to avg pool will be of shape (batch_size, 20, 5, 5)\n",
    "        self.avg1 = nn.AvgPool2d(5)\n",
    "        # (batch_size, 20, 1, 1)\n",
    "        # flatten to (batch_size, 20)\n",
    "        self.fc1 = nn.Linear(20, 10)\n",
    "        # output shape: (batch_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        c1 = self.block1(x)\n",
    "        c2 = self.block2(c1)\n",
    "        c3 = self.conv1(c2)\n",
    "        c4 = self.conv2(c3)\n",
    "        c5 = self.conv3(c4)\n",
    "        c6 = self.avg1(c5)\n",
    "        c6 = torch.flatten(c6, 1)\n",
    "        c7 = self.fc1(c6)\n",
    "        y = c7\n",
    "        \n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
