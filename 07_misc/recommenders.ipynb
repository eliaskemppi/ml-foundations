{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ace933",
   "metadata": {},
   "source": [
    "# Recommendation Systems\n",
    "\n",
    "A recommendation system predicts how much a user will like an item they haven't interacted with yet.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Netflix recommends movies\n",
    "\n",
    "- Spotify recommends songs\n",
    "\n",
    "Formally,\n",
    "\n",
    "$f(\\text{user, item}) = \\text{score}$\n",
    "\n",
    "Score here can be rating, click probability etc.\n",
    "\n",
    "#### Types of recommendation systems\n",
    "\n",
    "**Content Based**\n",
    "\n",
    "- Recommend items like other items you have liked (genre, director, description text etc.)\n",
    "\n",
    "**Collaborative Filtering**\n",
    "\n",
    "- Recommend based on other users' behavior. So recommend items that users like you liked.\n",
    "\n",
    "- Use **embeddings** for both the item and user\n",
    "\n",
    "- Dot product theses embeddings per user and item to get the prediction\n",
    "\n",
    "**Modern methods**\n",
    "\n",
    "- Combine the 2 methods above\n",
    "\n",
    "- You can also add additional context (device, time, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555cfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d304e",
   "metadata": {},
   "source": [
    "#### Example: Matrix Factorization\n",
    "\n",
    "| User / Item | Movie A | Movie B | Movie C |\n",
    "| ----------- | ------- | ------- | ------- |\n",
    "| User 1      | 5       | -       | 1       |\n",
    "| User 2      | -       | 4       | 2       |\n",
    "| User 3      | 1       | 5       | -       |\n",
    "\n",
    "We have a sparse matrix. We learn latent embeddings for both item and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# userid, itemid, rating\n",
    "data = torch.tensor([\n",
    "    [0, 0, 5.0],\n",
    "    [0, 2, 1.0],\n",
    "    [1, 1, 4.0],\n",
    "    [1, 2, 2.0],\n",
    "    [2, 0, 1.0],\n",
    "    [2, 1, 5.0],\n",
    "])\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        u = self.user_emb(user_ids)\n",
    "        i = self.item_emb(item_ids)\n",
    "        return (u * i).sum(dim=1) # row-wise dot product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787a007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 17.3294\n",
      "Epoch 100, Loss 0.1567\n",
      "Epoch 200, Loss 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_users = 3\n",
    "num_items = 3\n",
    "model = MatrixFactorization(num_users, num_items, embedding_dim=2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "loss_fn = nn.MSELoss()\n",
    "users = data[:, 0].long()\n",
    "items = data[:, 1].long()\n",
    "ratings = data[:, 2]\n",
    "\n",
    "# training loop\n",
    "for epoch in range(201):\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(users, items)\n",
    "    loss = loss_fn(preds, ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb4608",
   "metadata": {},
   "source": [
    "#### Printing User 1 predicted scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb9bce4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.0007, 11.4591,  0.9999], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "user_id = torch.tensor([0])\n",
    "all_items = torch.arange(num_items)\n",
    "\n",
    "scores = model(user_id.repeat(num_items), all_items)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea230aa",
   "metadata": {},
   "source": [
    "Now we can recommend items with the highest scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d305c",
   "metadata": {},
   "source": [
    "Dot products cannot capture non-linear interactions $\\rightarrow$ MLP\n",
    "\n",
    "#### Example: Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * emb_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        u = self.user_emb(user_ids)\n",
    "        i = self.item_emb(item_ids)\n",
    "        x = torch.cat([u, i], dim=1)\n",
    "        x = self.mlp(x).squeeze()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959cf61",
   "metadata": {},
   "source": [
    "While this captures nonlinearities, the MLP in the forward pass adds a lot of latency while serving recommendations if there are many items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cc033",
   "metadata": {},
   "source": [
    "#### Example: Two-Tower Models:\n",
    "\n",
    "Two-tower models use neural networks to learn user and item embeddings independently. The final relevance score is computed using a dot product.\n",
    "\n",
    "Because item embeddings do not depend on the user, they can be precomputed and stored in a vector index. At inference time, the system computes a single user embedding and retrieves the most similar items using approximate nearest-neighbor (ANN) search, reducing latency compared to scoring every item individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da0cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # User tower\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Embedding(num_users, emb_dim),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Item tower\n",
    "        self.item_tower = nn.Sequential(\n",
    "            nn.Embedding(num_items, emb_dim),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        u_vec = self.user_tower(user_ids)\n",
    "        i_vec = self.item_tower(item_ids)\n",
    "\n",
    "        return (u_vec * i_vec).sum(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
